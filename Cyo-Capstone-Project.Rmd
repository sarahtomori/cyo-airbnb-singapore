---
title: "Cya-harvard-airbnb"
author: "Sarah Tomori"
date: "04/01/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Overview
### 1.1 Introduction

This project is part of the Harvard course "Capstone", which is one of 9 required in order to obtain a professional certificate in Data Science. 

In this "Choose Your Own"-project, I have chosen to use the dataset from Kaggle.com, consisting of Airbnb data in Singapore. Airbnb has gained popularity all over the world and is among many travellers a preferred form of accomodation over hotels. Thus, the hotel industry faces a lot of competetion from these private house owners looking to rent out their homes to holiday visitors. 

### 1.2 Purpose of the project

The sharing economy is becoming more and more widespread not only through housing options such as Airbnb but also through services such as Uber and general ridesharing services, crowdfunding, knowledge sharing and many other fields. For this reason, it is a very interesting area to look into and discover how such prices are actually determined. 

Airbnb has, as mentioned, competed against many hotels due to there competitive prices and general flexibility. However, there are a various number of things could contribute to determining, how much should be charged for a visitor to stay in an Airbnb. Thus, the purpose of the project is to try to predict, which factors (variables) that affect the price of an Airbnb in Singapore and which machine learning algorithms do the best job at doing so.

In order to determine the best model, RMSE and R-squared will be used as to make informed decisions on the best model. The model that produces the lowest value of RMSE will be the final model and rerun on the test set in the end, which corresponds to the data that hasnâ€™t yet been touched by our model prior to this. The r-squared will also be used to give an indication of how much variation the model actually explains. 

## 2. Method and analysis

In this section, the Singapore Airbnb dataset is explored with the help of different visualisation tools and data cleansing. This is an important step prior to our analysis, as it helps us understand the structure of the data and minimize the risk of disturbances that could bias results when training the model to be used for predicting Airbnb prices.

### 2.1 Preparing the data

First, we need to install and load all the packages required.

```{r}
#Install required packages
#Download the packages
library("readr")
library("caret")
library("magrittr")
library("dplyr")
library("wordcloud")
library("SnowballC")
library("corrplot")
library("wesanderson")
library("maps")
library("mapproj")
library("ggmap")
library("tm")
library("Hmisc")
library("rpart")
library("rsq")
library("glmnet")
library("neuralnet")
```

Read the file with the Singapore Airbnb data.

```{r}
#Read the file with the Singapore Airbnb data. 

#Singapore data set loaded from:
#http://data.insideairbnb.com/singapore/sg/singapore/2019-11-26/visualisations/listings.csv

dl <- tempfile()
download.file("http://data.insideairbnb.com/singapore/sg/singapore/2019-11-26/visualisations/listings.csv", dl)

data <- read_csv(dl)
```

Then we need to create the test set, which will be 10% of the whole Airbnb Singapore data set. The test set will be kept till the very end and will ONLY be used to run the finally chosen algorithm on.

```{r}
# Create test set as 10% of the dataset
set.seed(1, sample.kind="Rounding")
test_index <- createDataPartition(y = data$price, times = 1, p = 0.1, list = FALSE)
airbnb_singapore <- data[-test_index,]
temp <- data[test_index,]
```

You need to make sure that the host id that is present in the test set is also present in training set.

```{r}
# Make sure that host_id in the test set are present in the airbnb_singapore set
test_set <- temp %>%
semi_join(airbnb_singapore, by = "host_id")
# Add rows removed from test set back into airbnb_singapore set
removed <- anti_join(temp, test_set)
airbnb_singapore <- rbind(airbnb_singapore, removed)
rm(temp, data, removed)
```

A validation set is also created and this set is meant to test the intermediary models when training, before deciding on the best and final model. The chosen final model will then be used on the test set.

```{r}
# Split airbnb_singapore data further in to validation and training sets
# Validation set will be 10% of current airbnb_singapore data
set.seed(1, sample.kind="Rounding")
# if using R 3.5 or earlier, use `set.seed(1)` instead
test_index2 <- createDataPartition(y = airbnb_singapore$price, times = 1, p = 0.1, list = FALSE)
train_set <- airbnb_singapore[-test_index2,]
temp2 <- airbnb_singapore[test_index2,]
```

As done with the creation of the test set, we need to make sure that host_id in the validation set is also in the training set.

```{r}
# Make sure host_id in validation is also in training set
validation <- temp2 %>% 
  semi_join(train_set, by = "host_id")
# Add rows removed from validation back into training set
removed <- anti_join(temp2, validation)
train_set <- rbind(train_set, removed)
rm(temp2, removed)
```

### 2.2 Data and exploration

#### 2.2.1 Overview

The next step is to explore the data before analysing it. As the data is taken from Kaggle.com and is ready to use, not much data cleaning was necessesary to do beforehand but we need to do quite a bit of visualisation.

#### 2.2.2 Data exploration

We are going to explore what kind of class our dataset falls into. Based in the class() function in RStudio, this is shown below. We can see that the data is a data frame.

```{r}
# Check class of data
class(airbnb_singapore)
```

We can see that our data is a data frame. Next, we can use the glimpse() function to get an overview of the different variables.

```{r}
# Get brief overview of the data
glimpse(airbnb_singapore)
```

From above, it is shown that data (without our test set which is kept for the end) contains 7,277 observations and there are 16 variables in the data set. id is used to identify the Airbnb listing and is unique for each listing. host_id is used to identify the host responsible for the respective listing. Thus, is is possible for a host to have more than one listing, if they are renting out more than one Airbnb.
 
Next, let's look at a summary of the data as well. 
```{r}
# See a summary of the data
summary(airbnb_singapore)
```

Looking at this summary, we see that the minimum minimum price shown is 0 Singaporean dollars per night while the maximum shown is 10000 Singaporean dollars per night. The maximum number of reviews found is 345, while the minimum is 0, due to some Airbnb's never having been reviewed.

```{r}
# Check whether there are any missing values
anyNA(airbnb_singapore)
```

There are some missing values in the dataset. We might have to process that later before starting the analysis.

We can also show the number of unique price values can be found in the dataset.

```{r}
# Show unique values of airbnb prices
unique(airbnb_singapore$price)

#Show the number of unique values of prices
n_distinct(unique(airbnb_singapore$price))
```

There is a great range of various unique prices, which is due to the continuous nature of this variable. In fact, there are 364 different prices in the dataset. This is just to get an overview, as counting the number of unique price values is not as explanative as doing so with discrete variables.

Next, we can show how many hosts, listings, regions, neighbourhoods and types of rooms the dataset contains in total.

```{r}
# Show number of hosts, listings, regions, neighbourhoods and room types
airbnb_singapore %>% summarise(n_hosts = n_distinct(host_id), n_listings = n_distinct(id),
n_regions = n_distinct(neighbourhood_group), n_neighbourhoods = n_distinct(neighbourhood),
n_types = n_distinct(room_type))
```

This shows that there are 2626 hosts, 7277 listings, 5 regions, 44 neighbourhoods and 3 types of rooms possible to rent. The fact that the number of hosts is less than half the number of listings, which confirms the earlier statement claiming that some hosts will likely be hosts for more than one rental or listing.

Next, we will look at the minimum nights required in order to stay in an Airbnb in Singapore.
```{r}
# Show average minimum nights required
mean(airbnb_singapore$minimum_nights)
```

The average minimum number of nights required to stay at an Airbnb is 18.4943 nights. This indicates that many owners require you to stay for a longer period of time in order to rent out their accommodation. However, it could also be an indication that there are many listings available on the Singaporean Airbnb platform with the purpose of long duration rental.

We can also show what the average price level is per night in Singapore.
```{r}
# Show average price per night
mean(airbnb_singapore$price)
```

The average price is 169.8464 Singaporean dollars.

### 2.3 Visualisation of the data

It is necessary to review how our data looks before we proceed to the analysing stage of the project. 

First, a histogram is created to show the distribution of prices among the various listings.
```{r}
# Price distributions in the training set
airbnb_singapore %>% ggplot(aes(price)) + geom_histogram(bins = 10, color = "#000000",
fill = "#FFCCCC") +
ggtitle("Distribution of prices across Airbnbs")
```

From the histogram above, we see that majority of the Airbnb listings are below a 1000 Singaporean dollars and only few are at much higher end of the scale. The further to the right one looks, the fewer Airbnbs are typically to find at that price level. It also shows that there are many various price levels once the Airbnb costs less than 25 Singaporean dollars per night.

Due to the continuous nature of the prices and the large variation in prices, it is a bit hard to interpret the above histogram. Instead, we can also see the top 20 most common prices.

```{r}
#Check the most common prices
most_common_prices <- airbnb_singapore %>% group_by(price) %>%
summarise(count = n()) %>% top_n(20, count) %>% arrange(desc(count))
most_common_prices
#Check median price
median(airbnb_singapore$price)
```

It is found that 50 Singaporean dollars is the most common price with 203 priced at this level. Secondly, 60 Singaporean dollars is commonly used to price Airbnbs as well. The median price for an Airbnb is 120 Singaporean dollars.

A display of the availability distribution can be shown as well.

```{r}
#Check distributions of availability in the training set
airbnb_singapore %>% ggplot(aes(availability_365)) + geom_histogram(bins = 20,
fill = "#009999") +
ggtitle("Availability")
```

The graph shows that while some are only available less than 300 days a year, the far majority of Airbnbs are actually available for rent all 365 days or at least close to that.

The distribution below shows the number of listings in each regions. Each listing has a unique id. Thus, by counting the id variable, we assume this will give us the total number of listings, as an Airbnb should only be listed on the website once.

```{r}
#Check distributions of listings in the various regions in training set
airbnb_singapore %>% ggplot(aes(neighbourhood_group)) + geom_bar(fill = "#3399FF") +
ggtitle("Number of listings in regions")
```

From the graph above, we can see that the most popular region with the highest number of Airbnbs is the Central Region. This could indicate this number being very popular tourist destinations but also that there are many houses available, where owners like to rent it out to temporary visitors. 

Next, let's see whether there is a difference in the average price levels across regions.

```{r}
#Check distributions of listings in the various regions in training set

avg_prices <- airbnb_singapore %>% group_by(neighbourhood_group) %>%
summarise(region_avg = mean(price)) %>%
arrange(-region_avg)
avg_prices
#Display them in a histogram
avg_prices %>% ggplot(aes(reorder(neighbourhood_group, region_avg), region_avg,
fill = region_avg)) +
geom_bar(stat = "identity") + coord_flip() +
scale_fill_distiller(palette = "YlOrRed") + labs(y = "Region price mean", x = "Region") +
ggtitle("Average Airbnb prices of regions")

```

From this, we see that the Central Region is on average the most expense region to rent an Airbnb in Singapore, followed by West Region, East Region, North-East Region and North Region, which is the cheapest.

Additionally, we can show the neighbourhoods with the most listings.
 
```{r}

#First, save the number of listings in each neighbourhood.

top_neighbourhoods <- airbnb_singapore %>% group_by(neighbourhood) %>%
summarise(count = n()) %>% top_n(20, count) %>% arrange(desc(count))
top_neighbourhoods

#We can also show them in a bar chart.

top_neighbourhoods %>% ggplot(aes(reorder(neighbourhood, count), count, fill = count)) +
geom_bar(stat = "identity") + coord_flip() +
scale_fill_distiller(palette = "Reds") + labs(y = "Number", x = "Neighbourhood") +
ggtitle("Popular neighbourhoods")

```

From this, we can see that some of the neighbourhoods with most listings are Kallang, Geylang, Novena, Rochor and Bukit Merah.

Let's try to see a distribution of the number of the different room types.

```{r}
#Check distributions of listings in the various room types in training set
airbnb_singapore %>% ggplot(aes(room_type)) + geom_bar(fill = "#9999FF") +
ggtitle("Number of listings in regions")
```

The most common room types are entire homes or apartments and private rooms. Hotel rooms and shared rooms are much less common.

We can also check the distribution of the number of reviews.

```{r}
#Check distributions of review count in the training set
airbnb_singapore %>% ggplot(aes(number_of_reviews)) + geom_histogram(bins = 30,
fill = "#009999") +
ggtitle("Reviews")
```

This shows that there are only very few who almost have up to a 5000 reviews, but most Airbnbs have below 1000 reviews. To be more specific, it is generally more common for the Airbnb's to have few or none reviews than to have a lot. This could be due to the large number of listings, leading to a great number of options for visitors. Therefore, some may not even get to be visited or reviewed very often or at all.

It's also interesting to look at which words are most commonly used in the Airbnb titles.

First, we need to clean the text. I first saved the columns with the Airbnb names as a text file.
```{r}
#Now, we import the text file with the Airbnb names. We can read the file from GitHub
filePath <-
"https://raw.githubusercontent.com/sarahtomori/cyo-airbnb-singapore/master/singapore-airbnb-names.txt"
text <- readLines(filePath)

#Read the data as a corpus
docs <- Corpus(VectorSource(text))
```


Now, the text can be transformed, which is done using tm_map in order to replace special characters that could be found in the text. These could make it harder to analyse on the words. 

```{r}
#Replace special characters with text
#Replace special characters with text
toSpace <- content_transformer(function (x, pattern) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "[[:punct:]]")
```

The next step is to further clean the text. This among others includes converting to lower case and removing numbers.

```{r}
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2")) 
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
# docs <- tm_map(docs, stemDocument)
```

Afterwards, we can create a matrix that contains the frequence of the words. 
```{r}

#First, create a matrix that contains the frequency of the words. 
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m), decreasing=TRUE)
d <- data.frame(word = names(v), freq=v)
head(d, 10)

#Create a wordcloud that visualises the most common words used to describe the Airbnbs. 
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35, 
colors=brewer.pal(8, "Dark2"))

```

The largest letter words, are the ones most often found in name descriptions of the listings.

We can also see the 10 words that are used most frequently. We can use the following code:

```{r}
#Show the 10 most frequently used words.
head(d, 10)

#and plot them
barplot(d[1:10,]$freq, las = 2, names.arg = d[1:10,]$word,
col ="#FF9999", main ="Most frequent words",
ylab = "Word frequencies")

```


Another step that is necessary before deciding how to predict Airbnb prices is to check how many of the variables are correlated with each other. If two or more variables are highly correlated, this could dilute the influence that the individual variable has on Airbnb prices, as they could 
initially explain the same thing. Note that only the numerical values are applied in this plot.


```{r}
#Check whether the variables are correlated.

cordata <- airbnb_singapore[, c(1,3,7,8,10,11,12,14,15,16)]
head(cordata)

cordata.cor = cor(cordata, method = c("spearman"))
cordata.rcorr = rcorr(as.matrix(cordata))
cordata.rcorr

#Next, the following code can be used to extract the p-values from the data, using the following code:
cordata.coeff = cordata.rcorr$r
cordata.coeff

cordata.p = cordata.rcorr$P
cordata.p

#The correlation plot can be visualised using the corrplot() function
corrplot(cordata.cor)

```

The correlation matrix above shows the variables that are positively correlated on a red sclae and the negatively correlated variables as blue scale.

## 3. Data analysis

Now that we have reviewed and visualised the data, it is time to decide, which algorithm that does the best job at predicting the price of renting an Airbnb in Singapore. It was quite clear that it is a regression problem, as we are interested in predicting Airbnb price, which is a continuous variable.

I first tried to look at the basic mean of prices.

Afterwards, a basic linear regression model (OLS regression) was tested and then the Ridge regression model.

In order to evaluate the best model, RMSE (residual mean squared error) was used to choose the model with the smallest loss, because this is what determines how close it is to predicting actual prices. R-squared is also used to predict, how much of the variation the algorithm manages to predict.

We can define the function for calculating RMSE as written below.

```{r}
#First, we define the function that calculates RMSE
RMSE <- function(true_price, predicted_price){
sqrt(mean((true_price - predicted_price)^2, na.rm=T))
}
```

### 3.1 The most basic mean

If we were to take the most basic guess, we would simply guess the price to be the average of all prices of listed Airbnb in Singapore. This value is calculated below.

```{r}
#Calculate average price of Airbnb prices in Singapore

avg_price <- mean(airbnb_singapore$price)
avg_price

```

In this case, the squared loss would be
```{r}
#Check squared loss
mean((avg_price - validation$price)^2)
RMSE(validation$price, avg_price)
```

This squared loss is huge and obviously a very poor estimate of predicting the price of an Airbnb in Singapore. RMSE of 180.3126 also indicates quite a bit of error from the actual price.

Prices will vary a lot depending on various factors, so the mean is not at all a good estimate. In other words, many prices will vary from the mean and the sum of these differences will eventually add up to a large number as seen above.

### 3.1 The linear regression model

First, we can try commonly used linear regression model. This is often used to for ML predictions but is a very simple model that works particularly well if there is a high level of linearity.

Due to a lot of challenges with processing missing values, I decided to set the NA's of the 'last_review' variable to the same date of the first review in the data set. For other variables they were set to 0.

```{r}
#Replace missing values in the last_review variable with the date of the first review
airbnb_singapore$last_review <- ifelse(is.na(airbnb_singapore$last_review),
as.Date(2013-10-21,  origin = "2013-10-21", tz = "GMT"), airbnb_singapore$last_review)

airbnb_singapore[is.na(airbnb_singapore)] <- 0
```

For variables that are characters, they are converted to factors. It is also important to ensure that the training set and the validation set have the same levels to avoid problems when running the models later on.

```{r}
#Save neighbourhood, neighbourhood_group and room_type variables as factor in training and validation sets
validation$neighbourhood <- as.factor(validation$neighbourhood)
airbnb_singapore$neighbourhood <- as.factor(airbnb_singapore$neighbourhood)
validation$room_type <- as.factor(validation$room_type)
airbnb_singapore$room_type <- as.factor(airbnb_singapore$room_type)
validation$neighbourhood_group <- as.factor(validation$neighbourhood_group)
airbnb_singapore$neighbourhood_group <- as.factor(airbnb_singapore$neighbourhood_group)

#Create lm model
fit <- lm(price ~ host_id + longitude + latitude + latitude + number_of_reviews +
calculated_host_listings_count + neighbourhood_group + neighbourhood + room_type +
calculated_host_listings_count + availability_365, data = airbnb_singapore)
#use backward elimination to remove redundant variables
step(fit, direction = "backward", trace = FALSE) 

#add levels of 'neighbourhood' in 'validation' dataset to fit$xlevels[["neighbourhood"]]
fit$xlevels[["neighbourhood"]] <- union(fit$xlevels[["neighbourhood"]],
levels(validation[["neighbourhood"]]))

#add levels of 'room_type' in 'validation' dataset to fit$xlevels[["room_type"]] as well
fit$xlevels[["room_type"]] <- union(fit$xlevels[["room_type"]],
levels(validation[["room_type"]]))

#add levels of 'neighbourhood_group' in 'validation' dataset to fit object as well
fit$xlevels[["neighbourhood_group"]] <- union(fit$xlevels[["neighbourhood_group"]],
levels(validation[["neighbourhood_group"]]))
```

Now, we can define and run the lm model. Backward elimination was used to remove redundant variables.

```{r}
#Set seed
set.seed(1)

#Create lm model
fit <- lm(price ~ host_id + longitude + latitude + latitude + number_of_reviews +
calculated_host_listings_count + neighbourhood_group + neighbourhood + room_type +
calculated_host_listings_count + availability_365, data = airbnb_singapore)
#use backward elimination to remove redundant variables
step(fit, direction = "backward", trace = FALSE)

#Let's look at the coefficients
fit$coefficients

#Use the predict function
y_hat <- predict(fit, validation)
```

Next, we can see whether this model does any better than the basic mean by looking at our MSE, RMSE and r-squared.

```{r}
#Check squared loss
mean((y_hat - validation$price)^2)
RMSE(validation$price, y_hat)
#and the r-squared
rss_lm <- sum((validation$price - y_hat) ^ 2)  ## residual sum of squares
tss_lm <- sum((validation$price - mean(y_hat)) ^ 2)  ## total sum of squares
rsq_lm <- 1 - rss_lm/tss_lm
rsq_lm
```


RMSE is 160.6531, which is just a bit lower than what the earlier calculated mean. R-squared is 0.2061545, so the model only explains about 21% of the variation from predicted prices.

### 3.1 The ridge regression model

Next, the ridge regression model can be used to see if it gives us a better result. The ridge regression is often used in order to deal with the problem of multicollinearity. It uses L2 regularization to penalize the square of magnitude for the coifficients in the regression in order to minimize them.

The formula looks as written below:
LS Obj + L (sum of the square of coefficients)

where L is lambda. If L = 0, then our output will be similar to that of a basic linear regression.

If L is large, then coefficients will move towards zero. The glmnet package in R is used.

Note: I decided the last_review variable as it contains similar information as number of reviews, and it caused a lot of issues with NAs.

First, we need to define the independent variables.

```{r}
#Define the independent variables
x_var <- model.matrix(airbnb_singapore$price ~ longitude + number_of_reviews +
neighbourhood_group + calculated_host_listings_count + room_type + availability_365,
data = airbnb_singapore)

#Define the dependent variable
y_var <- airbnb_singapore$price

# Setting the range of lambda values
lambda_seq <- 10^seq(2, -2, by = -.1)

train_data <- data.frame(x_var, y_var)

model_glmnet <- train(y_var ~ ., data = train_data,
method = "glmnet",
metric = "RMSE",
na.action = na.replace,
lambda  = lambda_seq
)
```

We can check to see what the model looks like.

```{r}
#Check the model
summary(model_glmnet)
model_glmnet
```

We see the different variables for lambda.

```{r}
#Set seed
set.seed(1)

#Choose the optimal lambda value
# Using cross validation glmnet
ridge_cv <- cv.glmnet(x_var, y_var, lambda = lambda_seq)
# Best lambda value
best_lambda <- ridge_cv$lambda.min
best_lambda

```

Cross validation was necessary in order to punish the loss function of high coefficient values in the model. By using cross validation and finding the best_lambda, we see that the lambda providing the best value of RMSE was 0.01.

Next, we continue to build the final model.

```{r}
#Find the best ridge model
best_ridge <- glmnet(x_var, y_var, alpha = 0, lambda =  best_lambda)

#Get the coefficients
coef(best_ridge)

```

After fitting the best lambda on the training set, the predict function can be used to fit the ridge regression on the validation set.

```{r}
#Define y and x variables from the validation set
y_val <- validation$price
x_val <- model.matrix(validation$price ~ longitude + number_of_reviews +
calculated_host_listings_count + neighbourhood_group + room_type
+ availability_365, data = validation)

#Save as a data frame
val_data <- data.frame(x_val, y_val)

#Save the data in a data frame
val_data <- data.frame(x_val, y_val)

#Use predict function and fit to validation data
glmnet_pred_val <- predict(best_ridge, s = best_lambda, newx = x_val)
```

Let's try to see the values of RMSE and r-squared.

```{r}
#Calculate the MSE
mean((glmnet_pred_val - y_val)^2)
#and the RMSE
RMSE(validation$price, glmnet_pred_val)
#and the r-squared
rss <- sum((glmnet_pred_val - y_val) ^ 2)  ## residual sum of squares
tss <- sum((y_val - mean(glmnet_pred_val)) ^ 2)  ## total sum of squares
rsq <- 1 - rss/tss
rsq
```

It appears that the values of r-square and RMSE are doing worse when using the ridge regression. This indicates that tuning the parameters with this method does not help at predicting the prices better than the linear regression model. The basic linear regression model has a RMSE that is indeed lower than that of the ridge regression model.

Since we know that the linear basic regression model appears to be better than the ridge regression at predicting price, we can try to run it on the test set (our saved piece for the final model, which hasn't been touched throughout this report).

```{r}

#Use lm model created earlier and fit to validation data
y_test <- predict(fit, test_set)

```

Next, we can determine the values RMSE and rsq.

```{r}
#Calculate the MSE
mean((y_hat - test_set$price)^2)
#and the RMSE
RMSE(test_set$price, y_test)
#and the r-squared
rss <- sum((y_test - test_set$price) ^ 2)  ## residual sum of squares
tss <- sum((test_set$price - mean(y_test)) ^ 2)  ## total sum of squares
rsq <- 1 - rss/tss
rsq
```

After running the lm on the test set, we get an R-square of 0.2743, indicating that the linear regression model managed to explain nearly 27.5% of variation in prices of Airbnb's in Singapore. This can be significantly better but it gave a better result than the former ridge regression model, indicating that tuning the coefficients did not help improve our outcome in this case.

The factors affecting the Airbnb prices appeared to be longitude, number of reviews, calculated host listings, neighbourhood group, room type and availability_365.

## 4. Conclusion

From the analysis it can be concluded that ridge regression in this case did not do a better job at predicting the price of Airbnb's in Singapore. Linear regression overall had a better performance. 

It is important to note that there are many other ways that could improve the model even further. Due to time constraints, it was out of scope for the project at this time, but for future reference, other, more advanced methods could have been useful trying. This includes ensembling models. 


